{
    "versions": {
        "layer": "4.3",
        "navigator": "4.6.4"
    },
    "domain": "atlas-atlas",
    "metadata": [
        {
            "name": "url",
            "value": "https://atlas.mitre.org/studies/AML.CS0015"
        },
        {
            "name": "atlas_data_version",
            "value": "4.0.0"
        },
        {
            "name": "generated_on",
            "value": "2022-07-27"
        }
    ],
    "name": "Tesla Auto Wiper and Enhanced Autopilot Attack",
    "description": "Tesla Auto Wipers and Enhanced Autopilot driving mode both make use of computer vision machine learning models to determine the vehicle's corresponding functions. These functions can be exploited by physical adversarial machine learning attacks that affect the operation and the safety of the vehicle. While exploits to gain root access to the Tesla firmware had since been patched, the vulnerabilities to the underlying machine learning systems discovered by this research were still exploitable.",
    "techniques": [
        {
            "techniqueID": "AML.T0012",
            "showSubtechniques": false,
            "tactic": "initial-access",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0013",
            "showSubtechniques": false,
            "tactic": "discovery",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0047",
            "showSubtechniques": false,
            "tactic": "ml-model-access",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0040",
            "showSubtechniques": false,
            "tactic": "ml-model-access",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0043.001",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0043",
            "showSubtechniques": true,
            "tactic": "ml-attack-staging"
        },
        {
            "techniqueID": "AML.T0041",
            "showSubtechniques": false,
            "tactic": "ml-model-access",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0042",
            "showSubtechniques": false,
            "tactic": "ml-attack-staging",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0015",
            "showSubtechniques": false,
            "tactic": "impact",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0043.001",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0043",
            "showSubtechniques": true,
            "tactic": "ml-attack-staging"
        },
        {
            "techniqueID": "AML.T0042",
            "showSubtechniques": false,
            "tactic": "ml-attack-staging",
            "color": "#C8E6C9"
        },
        {
            "techniqueID": "AML.T0015",
            "showSubtechniques": false,
            "tactic": "impact",
            "color": "#C8E6C9"
        }
    ],
    "legendItems": [
        {
            "label": "Used in case study",
            "color": "#C8E6C9"
        }
    ]
}